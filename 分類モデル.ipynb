{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "分類モデル",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "18_y5t1Z-ntv-zbYFX5ITAb5GEyLNC0dj",
      "authorship_tag": "ABX9TyNDp68fKAkaYzUM+iP7IdYV",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ko-maki/code/blob/master/%E5%88%86%E9%A1%9E%E3%83%A2%E3%83%87%E3%83%AB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WImHxdys2NsM"
      },
      "source": [
        "参考にしたサイトのURLは切れていました(2020年12月18日)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEcCvnHLUx71"
      },
      "source": [
        "!apt install aptitude\n",
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "!pip install mecab-python3==0.7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0E9tmvKU16F"
      },
      "source": [
        "#テキストを読み込む。\n",
        "#テキストは、ネットニュースの記事を用いる。\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czqjAsKtVDc9"
      },
      "source": [
        "!unzip \"/content/gdrive/MyDrive/texts.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrmKb5jFVpDG"
      },
      "source": [
        "!ls texts/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HXvWlceV66p"
      },
      "source": [
        "#以下、テキストの処理を行う。\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from glob import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIAYFuYgWAxe"
      },
      "source": [
        "#ディレクトリを取得する。\n",
        "directories = glob('texts/*')\n",
        "directories"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZqZ4P6gWRdk"
      },
      "source": [
        "#ファイル名を取得する。\n",
        "filepaths = glob('{}/*.txt'.format(directories[0]))\n",
        "filepaths[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKR4pgAsWFoL"
      },
      "source": [
        "#ファイルを読み込む。\n",
        "with open(filepaths[0], encoding='utf-8') as f:\n",
        "  text = ''.join(f.readlines()[2:]) ## URL等の先頭２行を除く。\n",
        "print(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdrgijCQ3bsc"
      },
      "source": [
        "#ディレクトリの番号を取得する。\n",
        "for (i, directory) in enumerate(directories):\n",
        "    print(i, directory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pu5BF3LxWk8N"
      },
      "source": [
        "#テキストを読み込み、ラベル付を行う。\n",
        "texts, labels = [], []\n",
        "for (i, directory) in enumerate(directories):\n",
        "    #各ディレクトリ内のtxtファイルのパスをすべて取得\n",
        "    filepaths = glob('{}/*.txt'.format(directory))\n",
        "    # テキストを読み込んで、内容をtextに格納、ラベルも併せて格納\n",
        "    for filepath in filepaths:\n",
        "        with open(filepath, encoding='utf-8') as f:\n",
        "            text = ''.join(f.readlines()[2:])  # URL等の先頭２行を除いた各行の文章を連結して格納\n",
        "            texts.append(text)\n",
        "            labels.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSgxlYT2Wquh"
      },
      "source": [
        "#確認する。\n",
        "len(texts), len(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHe2qxQGWtTm"
      },
      "source": [
        "texts[3850]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoPPkYzEWxBE"
      },
      "source": [
        "labels[2849]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-aJaDh1W0HM"
      },
      "source": [
        "#形態素解析を行う。\n",
        "import MeCab\n",
        "mecab = MeCab.Tagger('-Ochasen')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf6k0xqDW4vl"
      },
      "source": [
        "#名詞を格納する。\n",
        "def get_nouns(text):\n",
        "    nouns = []\n",
        "    res = mecab.parse(text)\n",
        "    words = res.split('\\n')[:-2]\n",
        "    for word in words:\n",
        "        part = word.split('\\t')\n",
        "        if '名詞' in part[3]:\n",
        "            nouns.append(part[0])\n",
        "    return nouns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-bCZfIeW8DH"
      },
      "source": [
        "word_collect = []\n",
        "for text in texts:\n",
        "    nouns = get_nouns(text)\n",
        "    word_collect.append(' '.join(nouns))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbwuOazz8OqO"
      },
      "source": [
        "#nouns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vV-al_4J8dmu"
      },
      "source": [
        "#word_collect"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSVMj_DxXFt2"
      },
      "source": [
        "#分析を行う。\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(min_df=20)\n",
        "x = vectorizer.fit_transform(word_collect)\n",
        "x = x.toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXjNR_r-XQUM"
      },
      "source": [
        "#len(vectorizer.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRNQA6UUXSwU"
      },
      "source": [
        "#len(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPqs916YXVBx"
      },
      "source": [
        "x = x.astype('float32')\n",
        "t = np.array(labels, 'int32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAteY-wDXXTC"
      },
      "source": [
        "#データを訓練用と検証用に分類する。\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, t_train, t_test = train_test_split(x, t, train_size=0.7, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_KMWu1NXbM_"
      },
      "source": [
        "#以下、モデルの定義を行う。\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck9e1PBoXdFe"
      },
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "def reset_seed(seed=0):\n",
        "    \n",
        "    os.environ['PYTHONHASHSEED'] = '0'\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhQUPU83Xiw2"
      },
      "source": [
        "_, n_input = x_train.shape\n",
        "n_output = len(np.unique(t_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDP_4vjqXlWZ"
      },
      "source": [
        "from tensorflow.keras import models, layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-fKE9TKXnS2"
      },
      "source": [
        "reset_seed(0)\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Dense(200, input_shape=(n_input, ), activation='relu'),\n",
        "    layers.Dense(n_output, activation='softmax')\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(lr=0.01)\n",
        "model.compile(loss='sparse_categorical_crossentropy', \n",
        "              optimizer=optimizer, \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aIZu04OXpp1"
      },
      "source": [
        "#モデルを学習させる。\n",
        "history = model.fit(x_train, t_train,\n",
        "          batch_size=100,\n",
        "          epochs=20,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, t_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRMAmbP3Xr30"
      },
      "source": [
        "# 学習結果を取得する。\n",
        "results = pd.DataFrame(history.history)\n",
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cc278QFHXxo4"
      },
      "source": [
        "# 損失を可視化する。\n",
        "results[['loss', 'val_loss']].plot(title='loss')\n",
        "plt.xlabel('epochs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gb5OWNpMX5tn"
      },
      "source": [
        "# 正解率を可視化する。\n",
        "results[['accuracy', 'val_accuracy']].plot(title='metric')\n",
        "plt.xlabel('epochs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SqAQ12giX94u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}